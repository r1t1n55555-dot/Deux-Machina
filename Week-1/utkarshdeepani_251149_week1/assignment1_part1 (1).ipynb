{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JD1TAEPaA00W"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "n_states = 16\n",
        "n_actions = 4\n",
        "goal_state = 15\n",
        "hole = [6,8,12,13]\n",
        "\n",
        "Q_table = np.zeros((n_states, n_actions))\n",
        "env = gym.make(\n",
        "    'FrozenLake-v1',\n",
        "    desc=None,\n",
        "    map_name=\"4x4\",\n",
        "    is_slippery=False,\n",
        ")\n",
        "\n",
        "\n",
        "def get_next_state(state, action):\n",
        "    row, col = divmod(state, 4)\n",
        "\n",
        "    if action == 0 and col > 0:\n",
        "        col -= 1\n",
        "    elif action == 1 and col < 3:\n",
        "        col += 1\n",
        "    elif action == 2 and row > 0:\n",
        "        row -= 1\n",
        "    elif action == 3 and row < 3:\n",
        "        row += 1\n",
        "\n",
        "    return row * 4 + col\n",
        "learning_rate = 0.8\n",
        "discount_factor = 0.95\n",
        "ep = 1000\n",
        "total_reward = 0\n",
        "eps_start= 0.9\n",
        "eps_end= 0.01\n",
        "eps_decay= 0.99\n",
        "\n",
        "for ep in range(ep):\n",
        "    current_state, info = env.reset()\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        epsilon = max(eps_end, eps_start * (eps_decay)**(ep))\n",
        "        if np.random.rand() < epsilon:\n",
        "            action = np.random.randint(0, n_actions)\n",
        "        else:\n",
        "            action = np.argmax(Q_table[current_state])\n",
        "\n",
        "        next_state, reward, terminated, truncated, info = env.step(action)\n",
        "        done = terminated or truncated\n",
        "\n",
        "        if next_state == goal_state:\n",
        "            reward = 10\n",
        "        elif next_state in hole:\n",
        "            reward = -1\n",
        "        else:\n",
        "            reward = 0\n",
        "\n",
        "        total_reward += reward\n",
        "\n",
        "        Q_table[current_state, action] += learning_rate * (\n",
        "            reward + discount_factor * np.max(Q_table[next_state])\n",
        "            - Q_table[current_state, action]\n",
        "        )\n",
        "\n",
        "        current_state = next_state\n",
        "np.save(\"q_table.npy\", Q_table)\n",
        "print(f\"Total reward after training: {total_reward}\")\n",
        "print(\"Training finished.\")\n",
        "print(\"Q-table:\")\n",
        "print(Q_table)\n",
        "optimal_actions = np.argmax(Q_table, axis=1)\n",
        "print(optimal_actions.reshape((4,4)))"
      ]
    }
  ]
}